{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "601ec81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe9dbb12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Number of segments</th>\n",
       "      <th>segments</th>\n",
       "      <th>united_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/choi\\1\\3-11\\0.ref</td>\n",
       "      <td>10</td>\n",
       "      <td>[Santa Barbara -- `` The present recovery move...</td>\n",
       "      <td>Santa Barbara -- `` The present recovery movem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/choi\\1\\3-11\\1.ref</td>\n",
       "      <td>10</td>\n",
       "      <td>[The vast Central Valley of California is one ...</td>\n",
       "      <td>The vast Central Valley of California is one o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/choi\\1\\3-11\\10.ref</td>\n",
       "      <td>10</td>\n",
       "      <td>[The bronchus and pulmonary artery in this lun...</td>\n",
       "      <td>The bronchus and pulmonary artery in this lung...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/choi\\1\\3-11\\11.ref</td>\n",
       "      <td>10</td>\n",
       "      <td>[The Fulton County Grand Jury said Friday an i...</td>\n",
       "      <td>The Fulton County Grand Jury said Friday an in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/choi\\1\\3-11\\12.ref</td>\n",
       "      <td>10</td>\n",
       "      <td>[Temperature of the wash and rinse waters is m...</td>\n",
       "      <td>Temperature of the wash and rinse waters is ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      File  Number of segments  \\\n",
       "0   data/choi\\1\\3-11\\0.ref                  10   \n",
       "1   data/choi\\1\\3-11\\1.ref                  10   \n",
       "2  data/choi\\1\\3-11\\10.ref                  10   \n",
       "3  data/choi\\1\\3-11\\11.ref                  10   \n",
       "4  data/choi\\1\\3-11\\12.ref                  10   \n",
       "\n",
       "                                            segments  \\\n",
       "0  [Santa Barbara -- `` The present recovery move...   \n",
       "1  [The vast Central Valley of California is one ...   \n",
       "2  [The bronchus and pulmonary artery in this lun...   \n",
       "3  [The Fulton County Grand Jury said Friday an i...   \n",
       "4  [Temperature of the wash and rinse waters is m...   \n",
       "\n",
       "                                         united_text  \n",
       "0  Santa Barbara -- `` The present recovery movem...  \n",
       "1  The vast Central Valley of California is one o...  \n",
       "2  The bronchus and pulmonary artery in this lung...  \n",
       "3  The Fulton County Grand Jury said Friday an in...  \n",
       "4  Temperature of the wash and rinse waters is ma...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choi_folder_path = \"data/choi\"\n",
    "\n",
    "# Function to extract segments from a file\n",
    "def extract_segments(file_path):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        segmented_text = file.read()\n",
    "\n",
    "    # Split the text by \"==========\" \n",
    "    segments = segmented_text.strip().split(\"==========\")\n",
    "\n",
    "    # Remove any  whitespace from each segment and remove empty segments\n",
    "    segments = [segment.strip() for segment in segments if segment.strip()]\n",
    "    \n",
    "    return segments\n",
    "\n",
    "data = []\n",
    "\n",
    "# Walk through all subdirectories of choi folder\n",
    "for root, _, files in os.walk(choi_folder_path):\n",
    "    for file in files:\n",
    "        if file.endswith(\".ref\"):\n",
    "            file_path = os.path.join(root, file)\n",
    "            segments = extract_segments(file_path)\n",
    "            united_text = \" \".join(segments)  # Combine segments into a single text\n",
    "            data.append({\n",
    "                \"File\": file_path,\n",
    "                \"Number of segments\": len(segments),\n",
    "                \"segments\": segments,\n",
    "                \"united_text\": united_text\n",
    "            })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# df.to_csv(\"segments_data_with_united_text.csv\", index=False)\n",
    "\n",
    "# Display the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ea4b50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, remPunct=True):\n",
    "    text = text.lower()\n",
    "    if remPunct:\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "def calculate_cohesion_gaps(text, w):\n",
    "    word_freqs = {}\n",
    "    words = text.split()\n",
    "\n",
    "    for i in range(len(words) - w + 1):\n",
    "        window = words[i:i + w]\n",
    "        word_freq = sum(window.count(word) for word in window)\n",
    "        word_freqs[i] = word_freq\n",
    "\n",
    "    cohesion_gaps = {}\n",
    "    for i in range(len(words) - w):\n",
    "        if i == 0:\n",
    "            cohesion_gaps[i] = 0\n",
    "        else:\n",
    "            cohesion_gaps[i] = abs(word_freqs[i] - word_freqs[i - 1])\n",
    "\n",
    "    return cohesion_gaps\n",
    "\n",
    "def calculate_cohesion_score(cohesion_gaps, k):\n",
    "    sorted_gaps = sorted(cohesion_gaps.values(), reverse=True)\n",
    "    k_percentile = int(math.ceil(k * len(sorted_gaps) / 100))\n",
    "    return sum(sorted_gaps[:k_percentile]) / k_percentile\n",
    "\n",
    "def topic_segmentation(text, w=100, k=10, s=20, num_topics=10):\n",
    "    text = preprocess_text(text)\n",
    "    words = text.split()\n",
    "\n",
    "    cohesion_gaps = calculate_cohesion_gaps(text, w)\n",
    "    cohesion_score = calculate_cohesion_score(cohesion_gaps, k)\n",
    "# this part of the code calculates and generates a list of candidate boundary positions based on the desired number of topics\n",
    "# and the minimum gap requirement. \n",
    "# These candidate boundary positions will be used to segment the text into topics during the algorithm's execution.\n",
    "\n",
    "\n",
    "    min_boundary_gap = len(words) // num_topics\n",
    "    boundaries = list(range(min_boundary_gap, len(words) - w + 1, min_boundary_gap))\n",
    "\n",
    "    topics = []\n",
    "    start = 0\n",
    "    for boundary in boundaries:\n",
    "        topics.append(' '.join(words[start:boundary]))\n",
    "        start = boundary\n",
    "\n",
    "    topics.append(' '.join(words[start:]))\n",
    "\n",
    "    return topics\n",
    "\n",
    "# sample_text = \"\"\"Text segmentation, also known as text splitting, is the process of dividing a continuous text into segments or sections based on some patterns or criteria. These segments are intended to represent different topics or themes present in the text. Text segmentation is a common technique used in natural language processing (NLP) and information retrieval tasks.\n",
    "# There are several methods and algorithms for text segmentation. One such method is called TextTiling. TextTiling is a technique developed by Marti Hearst in 1994. It is mainly used for segmenting longer texts, such as essays, articles, or documents. TextTiling relies on finding patterns in word frequencies and co-occurrences to identify boundaries between different topics.\n",
    "# In this example, we will implement a basic Python code to perform topic segmentation without using NLTK's TextTilingTokenizer. Instead, we will implement the segmentation from scratch based on the TextTiling algorithm.\n",
    "# Let's get started with the implementation.\"\"\"\n",
    "\n",
    "# predicted_segments = topic_segmentation(sample_text, num_topics=10)\n",
    "# for i, topic in enumerate(predicted_segments, start=1):\n",
    "#     print(f\"Topic {i}:\")\n",
    "#     print(topic.strip())\n",
    "#     print(\"-----------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28555437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1:\n",
      "santa barbara the present recovery movement will gather steady momentum to lift the economy to a new historic peak by this autumn beryl w sprinkel economist of harris trust savings bank chicago predicted at the closing session here tuesday of investment bankers assn california group conference another speaker william h draper jr former under secretary of the army and now with the palo alto venture capital firm of draper gaither anderson urged the us to throw down the gauntlet of battle to communism and tell moscow bluntly we wo nt be pushed around any more he urged support for president kennedy s requests for both defense and foreign aid appropriations not flash in pan sprinkel told conferees that the recent improvement in economic activity was not a temporary flash in the pan but the beginning of a substantial cyclical expansion that will carry the economy back to full employment levels and witness a renewal of our traditional growth pattern\n",
      "-----------\n",
      "\n",
      "Topic 2:\n",
      "in view of the current expansion which promises to be substantial he said the odds appear to favor rising interest rates in coming months but there is reason to believe the change will not be as abrupt as in 1958 nor as severe as in late 1959 and 1960 mickey charles mantle the new york yankees man of muscle drives a home run 450 feet into the bleachers his feat touches upon the sublime when roger eugene maris mantle s muscular teammate powers four home runs in a doubleheader his performance merits awe but when tiny 145pound albert gregory pearson of the los angeles angels who once caught three straight fly balls in center field because as a teammate explained the other team thought no one was out there hits seven home runs in four months three more than his total in 1958 1959 and 1960 his achievement borders on the ridiculous cook had discovered a beef in his\n",
      "-----------\n",
      "\n",
      "Topic 3:\n",
      "possession a few days earlier and when he could not show the hide arrested him thinking the evidence insufficient to get a conviction he later released him even while suffering the trip to his home cook swore to moore and lane that he would kill the indian three weeks later following his recovery armed with a writ issued by the catskill justice on affidavits prepared by the district attorney cook and russell rode to arrest martinez arriving at daybreak they found julio in his corral and demanded that he surrender instead he whirled and ran to his house for a gun forcing them to kill him cook reported introduction in 1 we investigate a new series of line involutions in a projective space of three dimensions over the field of complex numbers these are defined by a simple involutorial transformation of the points in which a general line meets a nonsingular quadric surface bearing a curve of symbol afj\n",
      "-----------\n",
      "\n",
      "Topic 4:\n",
      "then in 2 we show that any line involution with the properties that a it has no complex of invariant lines and b its singular lines form a complex consisting exclusively of the lines which meet a twisted curve is necessarily of the type discussed in 1 no generalization of these results to spaces of more than three dimensions has so far been found possible 1 let q be a nonsingular quadric surface bearing reguli afj and afj and let zg be a afj curve of order k on q a philosopher may point out that the troubles of the congo began with the old adam and consequently will never end but a historian might put his finger on a specific man and date and hold out the hope that the troubles will sometime pass away the man was king leopold 2 of the belgians who in 1885 concluded that he had better grab a colony while the grabbing\n",
      "-----------\n",
      "\n",
      "Topic 5:\n",
      "was still good by force he took under his protection or stole 900000 square miles of wilderness in central africa this is an area nearly as large as western europe and it was filled then as now by quarreling tribes with no political or historical unity its boundaries had nothing to do with geography or ethnic groupings they were determined by the points at which leopold s explorers and gunmen got tired of walking the population of the congo is 135 million divided into at least seven major culture clusters and innumerable tribes speaking 400 separate dialects the religions of the people include christianity mohammedanism paganism ancestor worship and animism the climate ranges from the steamily equatorial to the temperate some who have written on utopia have treated it as a learned diversion of a learned world a phantasy with which more amused himself a holiday work a spontaneous overflow of intellectual high spirits a revel of debate paradox\n",
      "-----------\n",
      "\n",
      "Topic 6:\n",
      "comedy and invention with respect to this view two points are worth making first it appears to be based on the fact that on its title page utopia is described as festivus gay it overlooks the other fact that it is described as nec minus salutaris quam festivus no less salutary than gay miami fla march 17 the orioles tonight retained the distinction of being the only winless team among the eighteen majorleague clubs as they dropped their sixth straight spring exhibition decision this one to the kansas city athletics by a score of 5 to 3 indications as late as the top of the sixth were that the birds were to end their victory draught as they coasted along with a 3too advantage siebern hits homer over the first five frames jack fisher the big righthander who figures to be in the middle of oriole plans for a drive on the 1961 american league pennant held the a\n",
      "-----------\n",
      "\n",
      "Topic 7:\n",
      "s scoreless while yielding three scattered hits then dick hyde submarineball hurler entered the contest and only five batters needed to face him before there existed a 3to3 deadlock a tworun homer by norm siebern and a solo blast by bill tuttle tied the game and single runs in the eighth and ninth gave the athletics their fifth victory in eight starts greer garson worldfamous star of stage screen and television will be honored for the high standard in tasteful sophisticated fashion with which she has created a high standard in her profession as a neimanmarcus award winner the titianhaired miss garson is a personification of the individual look so important to fashion this season she will receive the 1961 oscar at the 24th annual neimanmarcus exposition tuesday and wednesday in the grand ballroom of the sheratondallas hotel the only woman recipient miss garson will receive the award with ferdinando sarmi creator of chic beautiful women s fashions harry\n",
      "-----------\n",
      "\n",
      "Topic 8:\n",
      "rolnick president of the byerrolnick hat corporation and designer of men s hats sydney wragge creator of sophisticated casuals for women and roger vivier designer of christian dior shoes paris france whose squared toes and lowered heels have revolutionized the shoe industry the silver and ebony plaques will be presented at noon luncheons by stanley marcus president of neimanmarcus beneficiary of the proceeds from the two showings will be the dallas society for crippled children cerebral palsy treatment center the attractive greer garson who loves beautiful clothes and selects them as carefully as she does her professional roles prefers timeless classical designs occasionally she deserts the simple and elegant for a fun piece simply because it s unlike me temperature of the wash and rinse waters is maintained at 85 90degreesf 29 32degreesc the top rolls are loaded with 40 lbs sixty lbs loading is possible but 40 lbs is adequate the suds box drain is arranged at the\n",
      "-----------\n",
      "\n",
      "Topic 9:\n",
      "start to deliver into the raised main drain pipe thus returning suds to soap box and the machine is started the 160ml bath containing the calculated amount of detergent is applied slowly and directly to the running specimen washing is continued for 30 minutes or for a period of time sufficient to allow 100 nips or passes through the squeeze rolls artists indeed turned to actual representations or molded threedimensional figures which were rare down to 800 bc they tended to reflect reality see plate 6a 9b a schematic abstract treatment of men and animals by intent rose only in the late eighth century to speak of this underlying view of the world is to embark upon matters of subjective judgment at the least however one may conclude that geometric potters sensed a logical order their principles of composition stand very close to those which appear in the homeric epics and the hexameter line their world again was a\n",
      "-----------\n",
      "\n",
      "Topic 10:\n",
      "still simple traditional age which was only slowly beginning to appreciate the complexity of life and perhaps an observer of the vases will not go too far in deducing that the outlook of their makers and users was basically stable and secure the storms of the past had died away and the great upheaval which was to mark the following century had not yet begun to disturb men s minds throughout the work of the later ninth century a calm severe serenity displays itself in the vases this spirit may perhaps at times bore or repel one in its internal selfsatisfaction but the best of the geometric pins have rightly been considered among the most beautiful ever made in the greek world the ninth century was in its artistic work the spiritually freest and most selfsufficient between past and future and the loving skill spent by its artists upon their products is a testimonial to their sense that what they were doing was important and was appreciated\n",
      "-----------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_segments = topic_segmentation(df['united_text'][0])\n",
    "for i, topic in enumerate(predicted_segments, start=1):\n",
    "    print(f\"Topic {i}:\")\n",
    "    print(topic.strip())\n",
    "    print(\"-----------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "341f0a52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4dc830c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['predicted_segments'] = df['united_text'].apply(topic_segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "735f8ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['predicted_segments_length'] = df['predicted_segments'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "875c3704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Number of segments</th>\n",
       "      <th>segments</th>\n",
       "      <th>united_text</th>\n",
       "      <th>predicted_segments</th>\n",
       "      <th>predicted_segments_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/choi\\1\\3-11\\0.ref</td>\n",
       "      <td>10</td>\n",
       "      <td>[Santa Barbara -- `` The present recovery move...</td>\n",
       "      <td>Santa Barbara -- `` The present recovery movem...</td>\n",
       "      <td>[santa barbara the present recovery movement w...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/choi\\1\\3-11\\1.ref</td>\n",
       "      <td>10</td>\n",
       "      <td>[The vast Central Valley of California is one ...</td>\n",
       "      <td>The vast Central Valley of California is one o...</td>\n",
       "      <td>[the vast central valley of california is one ...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/choi\\1\\3-11\\10.ref</td>\n",
       "      <td>10</td>\n",
       "      <td>[The bronchus and pulmonary artery in this lun...</td>\n",
       "      <td>The bronchus and pulmonary artery in this lung...</td>\n",
       "      <td>[the bronchus and pulmonary artery in this lun...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/choi\\1\\3-11\\11.ref</td>\n",
       "      <td>10</td>\n",
       "      <td>[The Fulton County Grand Jury said Friday an i...</td>\n",
       "      <td>The Fulton County Grand Jury said Friday an in...</td>\n",
       "      <td>[the fulton county grand jury said friday an i...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/choi\\1\\3-11\\12.ref</td>\n",
       "      <td>10</td>\n",
       "      <td>[Temperature of the wash and rinse waters is m...</td>\n",
       "      <td>Temperature of the wash and rinse waters is ma...</td>\n",
       "      <td>[temperature of the wash and rinse waters is m...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      File  Number of segments  \\\n",
       "0   data/choi\\1\\3-11\\0.ref                  10   \n",
       "1   data/choi\\1\\3-11\\1.ref                  10   \n",
       "2  data/choi\\1\\3-11\\10.ref                  10   \n",
       "3  data/choi\\1\\3-11\\11.ref                  10   \n",
       "4  data/choi\\1\\3-11\\12.ref                  10   \n",
       "\n",
       "                                            segments  \\\n",
       "0  [Santa Barbara -- `` The present recovery move...   \n",
       "1  [The vast Central Valley of California is one ...   \n",
       "2  [The bronchus and pulmonary artery in this lun...   \n",
       "3  [The Fulton County Grand Jury said Friday an i...   \n",
       "4  [Temperature of the wash and rinse waters is m...   \n",
       "\n",
       "                                         united_text  \\\n",
       "0  Santa Barbara -- `` The present recovery movem...   \n",
       "1  The vast Central Valley of California is one o...   \n",
       "2  The bronchus and pulmonary artery in this lung...   \n",
       "3  The Fulton County Grand Jury said Friday an in...   \n",
       "4  Temperature of the wash and rinse waters is ma...   \n",
       "\n",
       "                                  predicted_segments  \\\n",
       "0  [santa barbara the present recovery movement w...   \n",
       "1  [the vast central valley of california is one ...   \n",
       "2  [the bronchus and pulmonary artery in this lun...   \n",
       "3  [the fulton county grand jury said friday an i...   \n",
       "4  [temperature of the wash and rinse waters is m...   \n",
       "\n",
       "   predicted_segments_length  \n",
       "0                         10  \n",
       "1                         10  \n",
       "2                         10  \n",
       "3                         10  \n",
       "4                         10  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db97d721",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_boundaries(text):\n",
    "    boundaries = []\n",
    "    current_index = 0\n",
    "    for segment in text:\n",
    "        current_index += len(segment) + 1  # Add 1 for the period at the end of the sentence\n",
    "        boundaries.append(current_index - 1)  # Subtract 1 to get the index of the period\n",
    "    return boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7e05b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[956, 1828, 2740, 3568, 4524, 5393, 6359, 7338, 8263, 9215]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_boundaries = calculate_boundaries(df['predicted_segments'][0])\n",
    "predicted_boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee9c3392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1297, 1934, 2615, 3426, 4580, 5165, 6145, 7604, 8204, 9816]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_boundaries = calculate_boundaries(df['segments'][0])\n",
    "actual_boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45519eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['predicted_boundaries'] = df['predicted_segments'].apply(calculate_boundaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a03c54b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['actual_boundaries'] = df['segments'].apply(calculate_boundaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e3fbd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['predicted_boundaries'].apply(len) == df['actual_boundaries'].apply(len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "379ba536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Percentage Error: 20.39%\n"
     ]
    }
   ],
   "source": [
    "def calculate_percentage_error(predicted_values, actual_values):\n",
    "    if len(predicted_values) != len(actual_values):\n",
    "        raise ValueError(\"The predicted_values and actual_values lists must have the same length.\")\n",
    "\n",
    "    total_percentage_error = 0\n",
    "\n",
    "    for i in range(1, len(predicted_values)):\n",
    "        predicted = predicted_values[i]\n",
    "        actual = actual_values[i]\n",
    "        actual_previous = actual_values[i - 1]\n",
    "\n",
    "        if actual_previous == 0:\n",
    "            raise ValueError(\"Actual value cannot be zero.\")\n",
    "\n",
    "        segment_length = actual - actual_previous\n",
    "        percentage_error = abs(predicted - actual) / segment_length * 100\n",
    "        total_percentage_error += percentage_error\n",
    "\n",
    "    average_percentage_error = total_percentage_error / (len(predicted_values) - 1)  # Subtract 1 for segments\n",
    "    return average_percentage_error\n",
    "\n",
    "# Example usage:\n",
    "average_error = calculate_percentage_error(predicted_boundaries, actual_boundaries)\n",
    "print(f\"Average Percentage Error: {average_error:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60273521",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msalehi\\AppData\\Local\\Temp\\ipykernel_1668\\2603048561.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['average_percentage_error'] = df.apply(lambda row: calculate_percentage_error(row['predicted_boundaries'], row['actual_boundaries']), axis=1)\n"
     ]
    }
   ],
   "source": [
    "df['average_percentage_error'] = df.apply(lambda row: calculate_percentage_error(row['predicted_boundaries'], row['actual_boundaries']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b82c65e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1260, 2516, 3700, 4903, 6172, 7498, 8818, 10101, 11330, 12591]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['predicted_boundaries'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "acbc1d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1402, 2547, 4022, 5974, 7209, 8401, 9904, 11071, 12017, 13342]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['actual_boundaries'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5c8610cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58.200309760020495"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_percentage_error(df['predicted_boundaries'][1], df['actual_boundaries'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98ce6ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.20\n",
      "Precision: 0.20\n",
      "Recall: 0.20\n"
     ]
    }
   ],
   "source": [
    "def evaluate_segmentation_with_placement(actual_boundaries, predicted_boundaries, tolerance=100):\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    false_negatives = 0\n",
    "\n",
    "    for pred_boundary in predicted_boundaries:\n",
    "        closest_true_boundary = min(actual_boundaries, key=lambda x: abs(x - pred_boundary))\n",
    "        if abs(closest_true_boundary - pred_boundary) <= tolerance:\n",
    "            true_positives += 1\n",
    "            actual_boundaries.remove(closest_true_boundary)\n",
    "        else:\n",
    "            false_positives += 1\n",
    " \n",
    "    false_negatives = len(actual_boundaries)\n",
    "\n",
    "    accuracy = true_positives / len(predicted_boundaries)\n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "\n",
    "    return accuracy, precision, recall\n",
    "\n",
    "accuracy, precision, recall = evaluate_segmentation_with_placement(actual_boundaries, predicted_boundaries)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7165bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         True 1  True 2  True 3  True 4  True 5  True 6  True 7  True 8  True 9  True 10\n",
      "Pred 1   0.9084  0.1100  0.1568  0.1733  0.2376  0.0848  0.2243  0.2225  0.1670   0.2810\n",
      "Pred 2   0.3982  0.8412  0.2634  0.1578  0.2472  0.1173  0.2523  0.1785  0.1216   0.2375\n",
      "Pred 3   0.2409  0.1962  0.8695  0.4297  0.2403  0.0869  0.2289  0.1639  0.1404   0.2548\n",
      "Pred 4   0.2557  0.1754  0.1766  0.7209  0.5351  0.1537  0.2312  0.2366  0.1666   0.3026\n",
      "Pred 5   0.2166  0.1271  0.1368  0.1665  0.7426  0.4055  0.2262  0.2087  0.1796   0.2893\n",
      "Pred 6   0.2739  0.1529  0.1477  0.1675  0.2920  0.5564  0.7176  0.2338  0.2043   0.3158\n",
      "Pred 7   0.2478  0.1407  0.1487  0.1652  0.2455  0.0882  0.5060  0.6137  0.1693   0.2898\n",
      "Pred 8   0.2329  0.1146  0.1109  0.1578  0.2478  0.1280  0.2234  0.6983  0.4607   0.2465\n",
      "Pred 9   0.2703  0.1091  0.1594  0.1762  0.2732  0.1173  0.3017  0.2147  0.5624   0.6348\n",
      "Pred 10  0.3029  0.1549  0.1843  0.1918  0.3482  0.1189  0.3273  0.2591  0.2153   0.8767\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculate_similarity(predicted_segments, true_segments):\n",
    "    # Combine all segments into a single list for vectorization\n",
    "    all_segments = predicted_segments + true_segments\n",
    "\n",
    "    # Initialize a TF-IDF vectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # Calculate TF-IDF vectors for all segments\n",
    "    tfidf_matrix = vectorizer.fit_transform(all_segments)\n",
    "\n",
    "    # Calculate cosine similarity between predicted and true segments\n",
    "    similarity_matrix = cosine_similarity(tfidf_matrix[:len(predicted_segments)], tfidf_matrix[len(predicted_segments):])\n",
    "\n",
    "    return similarity_matrix\n",
    "# Example usage\n",
    "predicted_segments = predicted_segments\n",
    "true_segments = df['segments'][0]\n",
    "\n",
    "similarity_matrix = calculate_similarity(predicted_segments, true_segments)\n",
    "\n",
    "\n",
    "# Create a DataFrame in the desired format\n",
    "similarity_df = pd.DataFrame(similarity_matrix, columns=[f\"True {i}\" for i in range(1, len(true_segments) + 1)],\n",
    "                              index=[f\"Pred {i}\" for i in range(1, len(predicted_segments) + 1)])\n",
    "\n",
    "# Print the DataFrame on a single line with indexes\n",
    "print(similarity_df.to_string(header=True, float_format=\"{:.4f}\".format, index_names=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f3e79c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between True 1 and Pred 1: 0.9084\n",
      "Similarity between True 2 and Pred 2: 0.8412\n",
      "Similarity between True 3 and Pred 3: 0.8695\n",
      "Similarity between True 4 and Pred 4: 0.7209\n",
      "Similarity between True 5 and Pred 5: 0.7426\n",
      "Similarity between True 6 and Pred 6: 0.5564\n",
      "Similarity between True 7 and Pred 7: 0.5060\n",
      "Similarity between True 8 and Pred 8: 0.6983\n",
      "Similarity between True 9 and Pred 9: 0.5624\n",
      "Similarity between True 10 and Pred 10: 0.8767\n"
     ]
    }
   ],
   "source": [
    "# Get the minimum length between true_segments and predicted_segments\n",
    "min_length = min(len(true_segments), len(predicted_segments))\n",
    "\n",
    "# Iterate through the range of indices up to min_length to print similarity scores\n",
    "for i in range(min_length):\n",
    "    true_segment_label = f\"True {i + 1}\"\n",
    "    pred_segment_label = f\"Pred {i + 1}\"\n",
    "    similarity_score = similarity_df.loc[pred_segment_label, true_segment_label]\n",
    "    print(f\"Similarity between {true_segment_label} and {pred_segment_label}: {similarity_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe98714b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7282\n"
     ]
    }
   ],
   "source": [
    "# Get the minimum length between true_segments and predicted_segments\n",
    "min_length = min(len(true_segments), len(predicted_segments))\n",
    "all_similarity = []\n",
    "# Iterate through the range of indices up to min_length to print similarity scores\n",
    "for i in range(min_length):\n",
    "    true_segment_label = f\"True {i + 1}\"\n",
    "    pred_segment_label = f\"Pred {i + 1}\"\n",
    "    similarity_score = similarity_df.loc[pred_segment_label, true_segment_label]\n",
    "    all_similarity.append(similarity_score)\n",
    "Avg_similarity = round(np.mean(all_similarity),4)\n",
    "    \n",
    "#     print(f\"Similarity between {true_segment_label} and {pred_segment_label}: {similarity_score:.4f}\")\n",
    "print(Avg_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f246f86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msalehi\\AppData\\Local\\Temp\\ipykernel_1668\\3081751241.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['avg_similarity'] = df.apply(lambda row: calculate_similarity(row['predicted_segments'], row['segments']), axis=1)\n",
      "C:\\Users\\msalehi\\AppData\\Local\\Temp\\ipykernel_1668\\3081751241.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['avg_similarity'] = df['avg_similarity'].apply(lambda matrix: round(np.mean(np.diag(matrix)), 4))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Number of segments</th>\n",
       "      <th>segments</th>\n",
       "      <th>united_text</th>\n",
       "      <th>predicted_segments</th>\n",
       "      <th>predicted_segments_length</th>\n",
       "      <th>predicted_boundaries</th>\n",
       "      <th>actual_boundaries</th>\n",
       "      <th>average_percentage_error</th>\n",
       "      <th>avg_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/choi\\1\\3-11\\0.ref</td>\n",
       "      <td>10</td>\n",
       "      <td>[Santa Barbara -- `` The present recovery move...</td>\n",
       "      <td>Santa Barbara -- `` The present recovery movem...</td>\n",
       "      <td>[santa barbara the present recovery movement w...</td>\n",
       "      <td>10</td>\n",
       "      <td>[956, 1828, 2740, 3568, 4524, 5393, 6359, 7338...</td>\n",
       "      <td>[1297, 1934, 2615, 3426, 4580, 5165, 6145, 760...</td>\n",
       "      <td>20.39</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/choi\\1\\3-11\\1.ref</td>\n",
       "      <td>10</td>\n",
       "      <td>[The vast Central Valley of California is one ...</td>\n",
       "      <td>The vast Central Valley of California is one o...</td>\n",
       "      <td>[the vast central valley of california is one ...</td>\n",
       "      <td>10</td>\n",
       "      <td>[1260, 2516, 3700, 4903, 6172, 7498, 8818, 101...</td>\n",
       "      <td>[1402, 2547, 4022, 5974, 7209, 8401, 9904, 110...</td>\n",
       "      <td>58.20</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/choi\\1\\3-11\\10.ref</td>\n",
       "      <td>10</td>\n",
       "      <td>[The bronchus and pulmonary artery in this lun...</td>\n",
       "      <td>The bronchus and pulmonary artery in this lung...</td>\n",
       "      <td>[the bronchus and pulmonary artery in this lun...</td>\n",
       "      <td>10</td>\n",
       "      <td>[1025, 2107, 3143, 4275, 5324, 6338, 7422, 853...</td>\n",
       "      <td>[1644, 2083, 3350, 5123, 5789, 7114, 7741, 955...</td>\n",
       "      <td>53.62</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/choi\\1\\3-11\\11.ref</td>\n",
       "      <td>10</td>\n",
       "      <td>[The Fulton County Grand Jury said Friday an i...</td>\n",
       "      <td>The Fulton County Grand Jury said Friday an in...</td>\n",
       "      <td>[the fulton county grand jury said friday an i...</td>\n",
       "      <td>10</td>\n",
       "      <td>[728, 1403, 2107, 2822, 3602, 4268, 4960, 5679...</td>\n",
       "      <td>[1337, 1725, 2351, 2910, 3897, 4896, 5457, 652...</td>\n",
       "      <td>67.19</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/choi\\1\\3-11\\12.ref</td>\n",
       "      <td>10</td>\n",
       "      <td>[Temperature of the wash and rinse waters is m...</td>\n",
       "      <td>Temperature of the wash and rinse waters is ma...</td>\n",
       "      <td>[temperature of the wash and rinse waters is m...</td>\n",
       "      <td>10</td>\n",
       "      <td>[1081, 2314, 3458, 4662, 5863, 7063, 8300, 941...</td>\n",
       "      <td>[945, 1352, 2195, 4033, 5774, 7277, 8334, 9504...</td>\n",
       "      <td>54.67</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      File  Number of segments  \\\n",
       "0   data/choi\\1\\3-11\\0.ref                  10   \n",
       "1   data/choi\\1\\3-11\\1.ref                  10   \n",
       "2  data/choi\\1\\3-11\\10.ref                  10   \n",
       "3  data/choi\\1\\3-11\\11.ref                  10   \n",
       "4  data/choi\\1\\3-11\\12.ref                  10   \n",
       "\n",
       "                                            segments  \\\n",
       "0  [Santa Barbara -- `` The present recovery move...   \n",
       "1  [The vast Central Valley of California is one ...   \n",
       "2  [The bronchus and pulmonary artery in this lun...   \n",
       "3  [The Fulton County Grand Jury said Friday an i...   \n",
       "4  [Temperature of the wash and rinse waters is m...   \n",
       "\n",
       "                                         united_text  \\\n",
       "0  Santa Barbara -- `` The present recovery movem...   \n",
       "1  The vast Central Valley of California is one o...   \n",
       "2  The bronchus and pulmonary artery in this lung...   \n",
       "3  The Fulton County Grand Jury said Friday an in...   \n",
       "4  Temperature of the wash and rinse waters is ma...   \n",
       "\n",
       "                                  predicted_segments  \\\n",
       "0  [santa barbara the present recovery movement w...   \n",
       "1  [the vast central valley of california is one ...   \n",
       "2  [the bronchus and pulmonary artery in this lun...   \n",
       "3  [the fulton county grand jury said friday an i...   \n",
       "4  [temperature of the wash and rinse waters is m...   \n",
       "\n",
       "   predicted_segments_length  \\\n",
       "0                         10   \n",
       "1                         10   \n",
       "2                         10   \n",
       "3                         10   \n",
       "4                         10   \n",
       "\n",
       "                                predicted_boundaries  \\\n",
       "0  [956, 1828, 2740, 3568, 4524, 5393, 6359, 7338...   \n",
       "1  [1260, 2516, 3700, 4903, 6172, 7498, 8818, 101...   \n",
       "2  [1025, 2107, 3143, 4275, 5324, 6338, 7422, 853...   \n",
       "3  [728, 1403, 2107, 2822, 3602, 4268, 4960, 5679...   \n",
       "4  [1081, 2314, 3458, 4662, 5863, 7063, 8300, 941...   \n",
       "\n",
       "                                   actual_boundaries  \\\n",
       "0  [1297, 1934, 2615, 3426, 4580, 5165, 6145, 760...   \n",
       "1  [1402, 2547, 4022, 5974, 7209, 8401, 9904, 110...   \n",
       "2  [1644, 2083, 3350, 5123, 5789, 7114, 7741, 955...   \n",
       "3  [1337, 1725, 2351, 2910, 3897, 4896, 5457, 652...   \n",
       "4  [945, 1352, 2195, 4033, 5774, 7277, 8334, 9504...   \n",
       "\n",
       "   average_percentage_error  avg_similarity  \n",
       "0                     20.39            0.73  \n",
       "1                     58.20            0.83  \n",
       "2                     53.62            0.81  \n",
       "3                     67.19            0.72  \n",
       "4                     54.67            0.63  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_similarity(predicted_segments, true_segments):\n",
    "    # Combine all segments into a single list for vectorization\n",
    "    all_segments = predicted_segments + true_segments\n",
    "\n",
    "    # Initialize a TF-IDF vectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # Calculate TF-IDF vectors for all segments\n",
    "    tfidf_matrix = vectorizer.fit_transform(all_segments)\n",
    "\n",
    "    # Calculate cosine similarity between predicted and true segments\n",
    "    similarity_matrix = cosine_similarity(tfidf_matrix[:len(predicted_segments)], tfidf_matrix[len(predicted_segments):])\n",
    "\n",
    "    return similarity_matrix\n",
    "\n",
    "\n",
    "# Calculate average similarity for each row and add 'avg_similarity' column\n",
    "df['avg_similarity'] = df.apply(lambda row: calculate_similarity(row['predicted_segments'], row['segments']), axis=1)\n",
    "df['avg_similarity'] = df['avg_similarity'].apply(lambda matrix: round(np.mean(np.diag(matrix)), 4))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ebc14d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1297"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['segments'][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1dfdabe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7262494712103407"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['avg_similarity'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e35c9473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60.395165384593604"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['average_percentage_error'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "87f4d2a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.7860333282447101"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['average_percentage_error'].corr(df['avg_similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7f91b78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# def calculate_similarity(predicted_segments, true_segments):\n",
    "#     # Combine all segments into a single list for vectorization\n",
    "#     all_segments = predicted_segments + true_segments\n",
    "\n",
    "#     # Initialize a TF-IDF vectorizer\n",
    "#     vectorizer = TfidfVectorizer()\n",
    "\n",
    "#     # Calculate TF-IDF vectors for all segments\n",
    "#     tfidf_matrix = vectorizer.fit_transform(all_segments)\n",
    "\n",
    "#     # Calculate cosine similarity between predicted and true segments\n",
    "#     similarity_matrix = cosine_similarity(tfidf_matrix[:len(predicted_segments)], tfidf_matrix[len(predicted_segments):])\n",
    "\n",
    "#     return similarity_matrix\n",
    "\n",
    "# def calculate_metrics_for_pairs(similarity_matrix, threshold=0.7):\n",
    "#     metrics = []\n",
    "\n",
    "#     for i in range(similarity_matrix.shape[0]):\n",
    "#         similarity_score = similarity_matrix[i, i]\n",
    "#         true_positive = 1 if similarity_score >= threshold else 0\n",
    "#         false_positive = 1 - true_positive\n",
    "#         false_negative = 0  # We're only considering diagonal elements\n",
    "\n",
    "#         metrics.append((true_positive, false_positive, false_negative))\n",
    "\n",
    "#     return metrics\n",
    "# # Example usage\n",
    "# predicted_segments = predicted_segments\n",
    "# true_segments = df['segments'][0]\n",
    "\n",
    "# # Set the threshold for similarity scores\n",
    "# threshold = 0.7\n",
    "\n",
    "# # Calculate similarity matrix\n",
    "# similarity_matrix = calculate_similarity(predicted_segments, true_segments)\n",
    "\n",
    "# # Calculate metrics for each pair of \"True i\" and \"Pred i\"\n",
    "# metrics = calculate_metrics_for_pairs(similarity_matrix, threshold)\n",
    "\n",
    "# # Calculate overall metrics\n",
    "# true_positives = sum(tp for tp, _, _ in metrics)\n",
    "# false_positives = sum(fp for _, fp, _ in metrics)\n",
    "# false_negatives = sum(fn for _, _, fn in metrics)\n",
    "\n",
    "# accuracy = true_positives / (true_positives + false_positives + false_negatives)\n",
    "\n",
    "# precision_denominator = true_positives + false_positives\n",
    "# precision = true_positives / precision_denominator if precision_denominator != 0 else 0\n",
    "\n",
    "# recall_denominator = true_positives + false_negatives\n",
    "# recall = true_positives / recall_denominator if recall_denominator != 0 else 0\n",
    "\n",
    "# # Print the metrics for each pair and overall metrics\n",
    "# for i, (tp, fp, fn) in enumerate(metrics, start=1):\n",
    "#     print(f\"For True {i} and Pred {i}:\")\n",
    "#     print(f\"True Positives: {tp}, False Positives: {fp}, False Negatives: {fn}\\n\")\n",
    "\n",
    "# print(\"Overall Metrics:\")\n",
    "# print(\"Accuracy:\", accuracy)\n",
    "# print(\"Precision:\", precision)\n",
    "# print(\"Recall:\", recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab5e52f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
